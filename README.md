# 利用HOG+SVM识别手势
一共识别5种手势动作

1、加速 2、减速 3、停止 4、左转 5、右转
项目文件
项目文件列表如下：

data：存放训练集、测试集，实时保存的图像（用于在线检测）。
ges_ico：存放UI窗口使用的各种图标。
log：存放训练的CNN网络的模型参数。
CallFrame.py：界面窗口的逻辑文件，用来调用界面文件并编写信号与槽函数。
Frame.py：界面窗口的界面文件，通过PyQt5的designer工具生成。
GetTestImage.py：利用OpenCV获取图片并标记，用来制作测试集。
GetTrainImage.py：利用OpenCV获取图片并标记，用来制作训练集。
SaveGesture.py：利用OpenCV实时获取图片，并进行预处理，用于在线检测手势。
TestGesture.py：将实时获取的图片送入已训练好的CNN中判断其手势动作。
TestInTest.py：将测试集送入已训练好的CNN中判断该网络模型的准确率。
Train.py：训练CNN模型函数，并将训练好的模型参数保存在本地。
Train_inputdata.py：用来读取数据集的图像和标签，并打包成batch形式。
Train_model.py：模型结构，采用AlexNet结构。
使用方法
先用Train.py训练好模型参数，然后运行CallFrame.py调用出界面窗口， 点击窗口的相应按钮就可以在线检测手势动作，其中的执行手势按钮是和下位机通信（如STM32单片机）， 通过串口函数将识别结果传给下位机，实现根据手势动作控制的功能。

测试结果：
使用该模型训练到900步的时候在测试集上正确率可以稳定在95%左右。
（训练集：1，2,3，4号动作各有1300张照片，5号动作有1450张照片；测试集：每种动作各有200张照片）
